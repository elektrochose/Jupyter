{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNNs on GPU\n",
    "After 2 full days of Linux hell I got our Nvidia Tesla K40c to run with keras, and this will speed up computations significantly. Furthermore, I met with Jake Varley who works at Google Brain and knows his shit and he gave me a few tips. I will implement those here, and they are:  \n",
    "\n",
    "1) one-hot encoding over categorical variables  \n",
    "2) augment data by \"mirroring\" it, e.g. double the dataset by switching East and West labels since task is symmetrical  \n",
    "3) create 2 artificial datasets: one shuffled version where models should not be able to learn anything, and one \"hard-coded\" one where they should achieve perfect decoding score. This will be a sanity check   \n",
    "4) give more data to validation and test sets  \n",
    "5) only include last trial -- this point i'm less sure that I understand. from my understanding including a whole sequence is what gives the memory of the RNN the ability to learn chunks but we'll see. i'm going to try both 'last trial' and a sequence of length n.  \n",
    "6) switch dropout to 50%  \n",
    "7) increase batch size to 512  \n",
    "\n",
    "1-5 are about how we prepare the sequences. The last 2 are about the networks themeselves. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modules loaded...\n",
      "['DSR_TbyT_FirstTraining.p', 'DSR_TbyT_Naive_mPFC.p', 'DSR_TbyT_Naive_OFC.p', 'DSR_TbyT_MidTraining.p', 'DSR_TbyT_Saline.p', 'DSR_TbyT_MPFC.p', 'DSR_TbyT_OFC.p', 'DSR_TbyT_Ipsi.p', 'DSR_TbyT_Contra.p', 'PSR_TbyT_FirstTraining.p', 'PSR_TbyT_MidTraining.p', 'PSR_TbyT_Saline.p', 'PSR_TbyT_MPFC.p', 'PSR_TbyT_OFC.p', 'PSR_TbyT_Ipsi.p', 'PSR_TbyT_Contra.p', 'PSR_TbyT_Saline_Rigged.p', 'DSR_TbyT_Saline_Shuffled.p', 'PSR_TbyT_Saline_Shuffled.p']\n"
     ]
    }
   ],
   "source": [
    "#BOILERPLATE _______________________\n",
    "#MODULES ______________________\n",
    "ROOT = '/Users/pablomartin/python/'\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import operator\n",
    "import pysftp\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model\n",
    "\n",
    "from RNNmodule.SequenceClass import Sequences\n",
    "from behavioral_performance.utils import fileNames, fileNameLabels\n",
    "from Visualize.decoding import *\n",
    "idx = pd.IndexSlice\n",
    "RANDOM_STATE = 6\n",
    "print 'modules loaded...'\n",
    "\n",
    "fileNames.append('PSR_TbyT_Saline_Rigged.p')\n",
    "fileNames.append('DSR_TbyT_Saline_Shuffled.p')\n",
    "fileNames.append('PSR_TbyT_Saline_Shuffled.p')\n",
    "print fileNames\n",
    "datatype = ['Full', 'Last', 'Med']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Artificial Datasets\n",
    "First, let's create a shuffled dataset that no network could learn, so we have a baseline. We will make one for DSR_Saline and PSR_Saline, which are the 2 datasets with most data. We will keep all the trial information the same, but shuffle the labels.  \n",
    "Also, let's create a 'rigged' dataset that the network should be able to learn to perfection. We're gonna pick an XOR gate, where input A = last choice, input B = reward from penultimate trial. The prediction of this XOR model is highly counterintuitive and there is no chance that that is what rats do. Nonetheless, if we are implementing these models correctly, the network should disregard all the other data, find this pattern, and achieve perfect decoding. Otherwise, we are implementing everything wrong. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created shuffled datasets\n",
      "created rigged dataset\n"
     ]
    }
   ],
   "source": [
    "#load saline datasets\n",
    "DSR_Saline = pickle.load(open(ROOT + 'DATA_structures/TbyT/DSR_TbyT_Saline.p', 'rb'))\n",
    "PSR_Saline = pickle.load(open(ROOT + 'DATA_structures/TbyT/PSR_TbyT_Saline.p', 'rb'))\n",
    "#shuffle current choice - these are the eventual labels\n",
    "np.random.shuffle(DSR_Saline['choice',0].values)\n",
    "np.random.shuffle(PSR_Saline['choice',0].values)\n",
    "#save result\n",
    "pickle.dump(DSR_Saline, open(ROOT + 'DATA_structures/TbyT/DSR_TbyT_Saline_Shuffled.p', 'wb'))\n",
    "pickle.dump(PSR_Saline, open(ROOT + 'DATA_structures/TbyT/PSR_TbyT_Saline_Shuffled.p', 'wb'))\n",
    "print 'created shuffled datasets'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#rigged dataset - base will be PSR_Saline\n",
    "PSR_Saline = pickle.load(open(ROOT + \\\n",
    "                            'DATA_structures/TbyT/PSR_TbyT_Saline.p', 'rb'))\n",
    "fresh_copy = pickle.load(open(ROOT + \\\n",
    "                            'DATA_structures/TbyT/PSR_TbyT_Saline.p', 'rb'))\n",
    "choice_ch = np.sum(PSR_Saline['choice',0] == fresh_copy['choice', 0])\n",
    "reward_ch = np.sum(PSR_Saline['reward',0] == fresh_copy['reward', 0])\n",
    "print 'matching values choice: %i/%i' %(choice_ch, len(PSR_Saline))\n",
    "print 'matching values reward: %i/%i' %(reward_ch, len(PSR_Saline))\n",
    "for label, session in PSR_Saline.groupby(axis = 0, level = 'session'):\n",
    "\n",
    "    A = copy.deepcopy(session['reward', 0])\n",
    "    B = copy.deepcopy(session['choice', 0])\n",
    "    C = A + 2 * B\n",
    "    for trial in range(2, len(session)):\n",
    "        C.iloc[trial] = (C.iloc[trial - 1] + C.iloc[trial - 2]) % 4\n",
    "    A = C % 2\n",
    "    B = C > 1\n",
    "    print 'before assigning rigged list to original'\n",
    "    print 'A: %i/%i' %(np.sum(A == session['reward', 0]), len(session))\n",
    "    print 'B: %i/%i' %(np.sum(B == session['choice', 0]), len(session))\n",
    "\n",
    "    session['reward',0] = A\n",
    "    session['choice',0] = B\n",
    "    print 'after assigning rigged list to original'\n",
    "    print 'A: %i/%i' %(np.sum(A == session['reward', 0]), len(session))\n",
    "    print 'B: %i/%i' %(np.sum(B == session['choice', 0]), len(session))\n",
    "\n",
    "\n",
    "    PSR_Saline.loc[idx[label,:,:],idx['choice',0]] = session['choice',0]\n",
    "    PSR_Saline.loc[idx[label,:,:],idx['reward',0]] = session['reward',0]\n",
    "\n",
    "\n",
    "\n",
    "choice_ch = np.sum(PSR_Saline['choice',0] == fresh_copy['choice', 0])\n",
    "reward_ch = np.sum(PSR_Saline['reward',0] == fresh_copy['reward', 0])\n",
    "\n",
    "print 'matching values choice: %i/%i' %(choice_ch, len(PSR_Saline))\n",
    "print 'matching values reward: %i/%i' %(reward_ch, len(PSR_Saline))\n",
    "\n",
    "pickle.dump(PSR_Saline, open(ROOT + \\\n",
    "                        'DATA_structures/TbyT/PSR_TbyT_Saline_Rigged.p', 'wb'))\n",
    "print 'created rigged dataset'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Sequences\n",
    "Most of the fixes are in the preprocessing stage: preparing sequences. The data augmentation should be done *only* on the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset DSR_TbyT_Saline_Shuffled.p\n",
      "finished: DSR_TbyT_Saline_Shuffled.p - 1 - OneHotBinaryMinimal\n",
      "finished: DSR_TbyT_Saline_Shuffled.p - 30 - OneHotBinaryMinimal\n",
      "finished: DSR_TbyT_Saline_Shuffled.p - 200 - OneHotBinaryMinimal\n"
     ]
    }
   ],
   "source": [
    "seq_lengths = [1, 30, 200]\n",
    "seq_length_labels = ['Last', 'Med', 'Full']\n",
    "seq_types = ['OneHotBinaryMinimal']\n",
    "\n",
    "dataset_filenames = [w for w in os.listdir(ROOT + 'DATA_structures/TbyT/')\\\n",
    "                     if not w.startswith('.') and w!='DSR_TbyT_Naive_Saline.p']\n",
    "dataset_filenames = ['DSR_TbyT_Saline_Shuffled.p', 'PSR_TbyT_Saline_Shuffled.p', 'PSR_TbyT_Saline_Rigged.p']\n",
    "\n",
    "dataset_paths = [ROOT + 'DATA_structures/TbyT/' + w for w in dataset_filenames]\n",
    "\n",
    "mirrorFlag = True\n",
    "for dataset_file, dataset_path in zip(dataset_filenames, dataset_paths):\n",
    "    if not dataset_file.find('Rigged') < 0:\n",
    "        mirrorFlag = False\n",
    "    if not dataset_file.find('Shuffled') < 0:\n",
    "        mirrorFlag = False\n",
    "        \n",
    "    print 'dataset %s' %dataset_file\n",
    "    df = pickle.load(open(dataset_path, 'rb'))\n",
    "    for seq_length, seq_type in itertools.product(seq_lengths, seq_types):\n",
    "        seqObject = Sequences(seq_length, seq_type, RANDOM_STATE = RANDOM_STATE)\n",
    "        seqObject.create_sequences(df,\n",
    "                                   timesteps = seq_length,\n",
    "                                   feature_dim = seq_type,\n",
    "                                   validate_size = 0.25,\n",
    "                                   test_size = 0.25,\n",
    "                                   mirrorFlag = mirrorFlag)\n",
    "        seq_length_label =  seq_length_labels[seq_lengths.index(seq_length)]\n",
    "        pickle.dump(seqObject, open(ROOT + 'DATA_structures/RNN_sequences/' + \\\n",
    "                                            seq_type + '/' + \\\n",
    "                                            seq_length_label + '/' + \\\n",
    "                                            dataset_file, 'wb'))\n",
    "        print 'finished: %s - %s - %s' %(dataset_file, seq_length, seq_type)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Useful Tools\n",
    "Some tools that would be nice to have are the following:\n",
    "\n",
    "1) function that finds highest validation accuracy given a folder  \n",
    "2) plot training vs. validation accuracy and loss\n",
    "3) \n",
    "\n",
    "\n",
    "Let's use pysftp systematically for all this stuff. We're going to take the 10 highest performing models and train them for 1000 epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_val_acc(connection, model_dir):\n",
    "    if not connection.isdir(model_dir):\n",
    "        print 'model does not exist... exiting'\n",
    "        return None\n",
    "    model_files = connection.listdir(model_dir)\n",
    "    finished_training = sum([w=='loss_acc_history.p' for w in model_files])\n",
    "    if finished_training:\n",
    "        scores = dict([(index, float(w[w.find('-') + 1: -5]))\n",
    "                       for index, w in enumerate(model_files) if w.startswith('w')])\n",
    "        best_model = model_files[max(scores, key=scores.get)]\n",
    "        val_score = max(scores.values())\n",
    "        return val_score, best_model\n",
    "    else:\n",
    "        print 'training did not finish or has not begun...'\n",
    "        return None\n",
    "        \n",
    "        \n",
    "def retrieve_history(connection, model_dir, path_to_save_to = '.'):\n",
    "    if not connection.isdir(model_dir):\n",
    "        print 'model does not exist... exiting'\n",
    "        return \n",
    "    model_files = connection.listdir(model_dir)\n",
    "    finished_training = sum([w=='loss_acc_history.p' for w in model_files])\n",
    "    if finished_training:\n",
    "        connection.get(model_dir + 'loss_acc_history.p', path_to_save_to)\n",
    "        return \n",
    "    else:\n",
    "        print 'training did not finish or has not begun...'\n",
    "        return \n",
    "    \n",
    "    \n",
    "#this will plot standard training/validation progress thru epochs\n",
    "def plot_training_history(hist, title):\n",
    "    for field in hist.keys():\n",
    "        plt.plot(hist[field], label=field)\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('Accuracy / Loss')\n",
    "    plt.title(title, FontSize = 20)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "#downloads file, plots it, and then deletes file\n",
    "def plot_training_hist(connection, model_dir):\n",
    "    retrieve_history(connection, model_dir, path_to_save_to = '/Users/pablomartin/python/loss_acc_history.p')\n",
    "    hist = pickle.load(open('/Users/pablomartin/python/loss_acc_history.p', 'rb'))\n",
    "    plot_training_history(hist, model_dir)\n",
    "    os.remove('/Users/pablomartin/python/loss_acc_history.p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine Best Networks\n",
    "The following code uses a secure file transfer protocol (SFTP) connection into epsilon, finds out which models are done training, and evaluates which are the top ten performing models on the validation set. It saves this information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define parameters to iterate over\n",
    "epsilon_ROOT = '/home/pablo/python/'\n",
    "\n",
    "#CREATING NETWORK DIMENSIONS__________\n",
    "hidden_dimensions = [2, 5, 10, 20, 50, 100]\n",
    "hidden_dimensions_red = [5, 20, 50]\n",
    "\n",
    "HDS = np.zeros([69, 3], dtype = int)\n",
    "HDS[:len(hidden_dimensions), 0] = hidden_dimensions\n",
    "for index, (hd1, hd2) in enumerate(itertools.product(hidden_dimensions,\n",
    "                                                     hidden_dimensions)):\n",
    "    HDS[len(hidden_dimensions) + index, 0] = hd1\n",
    "    HDS[len(hidden_dimensions) + index, 1] = hd2\n",
    "\n",
    "counter = np.argmin(np.sum(HDS, axis = 1) != 0)\n",
    "for index, (hd1, hd2, hd3) in enumerate(itertools.product(hidden_dimensions_red,\n",
    "                                                          hidden_dimensions_red,\n",
    "                                                          hidden_dimensions_red)):\n",
    "    HDS[counter + index, 0] = hd1\n",
    "    HDS[counter + index, 1] = hd2\n",
    "    HDS[counter + index, 2] = hd3\n",
    "\n",
    "cellType_folders = {'RNN' : 'Models/RNN/OneHotBinaryMinimal/',\n",
    "                    'LSTM' : 'Models/LSTM/Pablo/OneHotBinaryMinimal/'}\n",
    "\n",
    "rows = pd.MultiIndex.from_product([datatype, [w[:-2] for w in fileNames]],\n",
    "                                  names =['Seq_Length', 'Dataset'])\n",
    "cols = pd.MultiIndex.from_product([['val_score', 'cell', 'network', 'dir_path', 'file_path'], range(1,11)],\n",
    "                                  names = ['Network Info', 'Rank'])\n",
    "MODEL_RESULTS = pd.DataFrame(np.zeros([len(rows), len(cols)]), index=rows, columns=cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "verbose = 0\n",
    "epsilon_connection = pysftp.Connection('10.81.104.156', username='pablo', password='pablo2014')\n",
    "epsilon2_connection = pysftp.Connection('10.81.104.143', username='pablo', password='pablo2015')\n",
    "remote_desktops = [epsilon2_connection]\n",
    "\n",
    "for connection, fileName, dataPrep in \\\n",
    "        itertools.product(remote_desktops, fileNames, ['Full', 'Med', 'Last']):\n",
    "\n",
    "    d = {}\n",
    "    print 'working on %s - %s' %(fileName, dataPrep)\n",
    "    for cell_type, hd in itertools.product(['RNN', 'LSTM'], HDS):\n",
    "        model_dir = epsilon_ROOT + cellType_folders[cell_type] + dataPrep + '/'\n",
    "        network_name = '_D_'.join([fileName[:-2]] + [str(w) for w in hd if w > 0])\n",
    "        model_dir += network_name\n",
    "        start = time.time()\n",
    "        if connection.isdir(model_dir):\n",
    "            tmp_val = retrieve_val_acc(connection, model_dir)\n",
    "        else:\n",
    "            tmp_val = None\n",
    "        if verbose > 1: print 'retrieval time: %.3f sec' %(time.time() - start)\n",
    "        if tmp_val:\n",
    "            val_score, best_model = tmp_val\n",
    "            d[best_model] = (val_score, cell_type, network_name)\n",
    "        \n",
    "    top_ten = sorted(d, key=lambda x:d[x][0])[-10:]\n",
    "    for index, key in enumerate(top_ten[::-1]):\n",
    "        dir_path = epsilon_ROOT \\\n",
    "                    + cellType_folders[d[key][1]] \\\n",
    "                    + dataPrep + '/' \\\n",
    "                    + d[key][2] + '/' \n",
    "        file_path = dir_path + key\n",
    "        if verbose: print 'model directory exists:%s' %connection.isdir(dir_path)\n",
    "        if verbose: print 'model exists:%s' %connection.isfile(file_path)\n",
    "        MODEL_RESULTS.loc[idx[dataPrep, fileName[:-2]], idx['val_score', 1 + index]] = d[key][0]\n",
    "        MODEL_RESULTS.loc[idx[dataPrep, fileName[:-2]], idx['cell', 1 + index]] = d[key][1]\n",
    "        MODEL_RESULTS.loc[idx[dataPrep, fileName[:-2]], idx['network', 1 + index]] = \\\n",
    "                                                            d[key][2][len(fileName[:-2]) + 1:]\n",
    "        MODEL_RESULTS.loc[idx[dataPrep, fileName[:-2]], idx['dir_path', 1 + index]] = dir_path\n",
    "        MODEL_RESULTS.loc[idx[dataPrep, fileName[:-2]], idx['file_path', 1 + index]] = file_path\n",
    "                                        \n",
    "                      \n",
    "MODEL_RESULTS.sort_index(axis = 0, inplace = True)\n",
    "MODEL_RESULTS.sort_index(axis = 1, inplace = True)\n",
    "print 'done'\n",
    "pickle.dump(MODEL_RESULTS, open('/Users/pablomartin/python/MODEL_RESULTS.p' ,'wb'))\n",
    "print MODEL_RESULTS.loc[idx[:,:], idx['val_score',1:5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Network Performance on Train, Validate, and Test\n",
    "Let's see how they generalize !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1278/1278 [==============================] - 2s 2ms/step\n",
      "315/315 [==============================] - 0s 312us/step\n",
      "289/289 [==============================] - 0s 333us/step\n",
      "738/738 [==============================] - 2s 3ms/step\n",
      "82/82 [==============================] - 0s 371us/step\n",
      "73/73 [==============================] - 0s 456us/step\n",
      "456/456 [==============================] - 2s 5ms/step\n",
      "65/65 [==============================] - 0s 345us/step\n",
      "56/56 [==============================] - 0s 328us/step\n",
      "1156/1156 [==============================] - 3s 2ms/step\n",
      "135/135 [==============================] - 0s 673us/step\n",
      "225/225 [==============================] - 0s 562us/step\n",
      "4248/4248 [==============================] - 4s 965us/step\n",
      "1161/1161 [==============================] - 1s 449us/step\n",
      "1040/1040 [==============================] - 0s 444us/step\n",
      "2124/2124 [==============================] - 4s 2ms/step\n",
      "267/267 [==============================] - 0s 597us/step\n",
      "286/286 [==============================] - 0s 568us/step\n",
      "1594/1594 [==============================] - 3s 2ms/step\n",
      "238/238 [==============================] - 0s 270us/step\n",
      "198/198 [==============================] - 0s 286us/step\n",
      "1768/1768 [==============================] - 3s 2ms/step\n",
      "271/271 [==============================] - 0s 223us/step\n",
      "196/196 [==============================] - 0s 273us/step\n",
      "1760/1760 [==============================] - 3s 2ms/step\n",
      "307/307 [==============================] - 0s 273us/step\n",
      "252/252 [==============================] - 0s 253us/step\n",
      "1126/1126 [==============================] - 3s 2ms/step\n",
      "165/165 [==============================] - 0s 260us/step\n",
      "239/239 [==============================] - 0s 238us/step\n",
      "downloading...10/19\n",
      "1448/1448 [==============================] - 3s 2ms/step\n",
      "186/186 [==============================] - 0s 280us/step\n",
      "243/243 [==============================] - 0s 306us/step\n",
      "downloading...11/19\n",
      "5646/5646 [==============================] - 6s 1ms/step\n",
      "1156/1156 [==============================] - 1s 578us/step\n",
      "1227/1227 [==============================] - 1s 586us/step\n",
      "downloading...12/19\n",
      "2144/2144 [==============================] - 3s 2ms/step\n",
      "336/336 [==============================] - 0s 304us/step\n",
      "286/286 [==============================] - 0s 308us/step\n",
      "downloading...13/19\n",
      "1528/1528 [==============================] - 3s 2ms/step\n",
      "243/243 [==============================] - 0s 268us/step\n",
      "242/242 [==============================] - 0s 288us/step\n",
      "downloading...14/19\n",
      "1692/1692 [==============================] - 3s 2ms/step\n",
      "295/295 [==============================] - 0s 253us/step\n",
      "235/235 [==============================] - 0s 243us/step\n",
      "downloading...15/19\n",
      "1798/1798 [==============================] - 3s 2ms/step\n",
      "301/301 [==============================] - 0s 234us/step\n",
      "225/225 [==============================] - 0s 252us/step\n",
      "downloading...16/19\n",
      "5646/5646 [==============================] - 4s 783us/step\n",
      "1156/1156 [==============================] - 0s 273us/step\n",
      "1227/1227 [==============================] - 0s 275us/step\n",
      "downloading...17/19\n",
      "4248/4248 [==============================] - 5s 1ms/step\n",
      "1161/1161 [==============================] - 0s 409us/step\n",
      "1040/1040 [==============================] - 0s 399us/step\n",
      "downloading...18/19\n",
      "5646/5646 [==============================] - 5s 954us/step\n",
      "1156/1156 [==============================] - 0s 410us/step\n",
      "1227/1227 [==============================] - 1s 417us/step\n",
      "                               train  validate      test\n",
      "DSR_TbyT_FirstTraining.p    0.830008  0.846825  0.825260\n",
      "DSR_TbyT_Naive_mPFC.p       0.865854  0.875000  0.883562\n",
      "DSR_TbyT_Naive_OFC.p        0.833882  0.865385  0.794643\n",
      "DSR_TbyT_MidTraining.p      0.831964  0.838889  0.835556\n",
      "DSR_TbyT_Saline.p           0.860464  0.865202  0.862260\n",
      "DSR_TbyT_MPFC.p             0.864054  0.869850  0.873252\n",
      "DSR_TbyT_OFC.p              0.865119  0.875000  0.851010\n",
      "DSR_TbyT_Ipsi.p             0.832862  0.856089  0.817602\n",
      "DSR_TbyT_Contra.p           0.841477  0.855863  0.823413\n",
      "PSR_TbyT_FirstTraining.p    0.800844  0.795455  0.796025\n",
      "PSR_TbyT_MidTraining.p      0.810946  0.788978  0.776749\n",
      "PSR_TbyT_Saline.p           0.781084  0.785251  0.775265\n",
      "PSR_TbyT_MPFC.p             0.795709  0.785714  0.790210\n",
      "PSR_TbyT_OFC.p              0.794993  0.787037  0.752066\n",
      "PSR_TbyT_Ipsi.p             0.774675  0.787288  0.765957\n",
      "PSR_TbyT_Contra.p           0.775584  0.796512  0.758889\n",
      "PSR_TbyT_Saline_Rigged.p    0.796936  0.795199  0.796047\n",
      "DSR_TbyT_Saline_Shuffled.p  0.750000  0.750000  0.750000\n",
      "PSR_TbyT_Saline_Shuffled.p  0.750000  0.750000  0.750000\n"
     ]
    }
   ],
   "source": [
    "MODEL_RESULTS = pickle.load(open('/Users/pablomartin/python/MODEL_RESULTS.p','rb'))\n",
    "dataPrep = 'Med'\n",
    "remote = 'epsilon2'\n",
    "\n",
    "desktops = {'epsilon1': {'ip': '10.81.104.153', 'password' : 'pablo2014'},\n",
    "            'epsilon2': {'ip': '10.81.104.143', 'password' : 'pablo2015'}}\n",
    "\n",
    "scores = pd.DataFrame(np.zeros([len(fileNames),4]),\n",
    "                      index = fileNames,\n",
    "                      columns = ['train','validate','test', 'model'])   \n",
    "\n",
    "for index, fileName in enumerate(fileNames):\n",
    "    \n",
    "    sequence_path = '/Users/pablomartin/python/' + \\\n",
    "                    'DATA_structures/RNN_sequences/OneHotBinaryMinimal/' + \\\n",
    "                    dataPrep + '/' + fileName\n",
    "    seqs = pickle.load(open(sequence_path, 'rb'))       \n",
    "\n",
    "    file_path = MODEL_RESULTS.loc[idx[dataPrep, fileName[:-2]], idx['file_path',1]]\n",
    "    model_target = '/Users/pablomartin/python/Models/Winners/' + fileName[:-2] + '.hdf5'\n",
    "    scores.loc[fileName, 'model'] = file_path\n",
    "    file_weights = file_path[-file_path[::-1].find('/'):]\n",
    "    #downloading model if not available in local machine\n",
    "    with pysftp.Connection(desktops[remote]['ip'],\n",
    "                           username='pablo',\n",
    "                           password=desktops[remote]['password']) as connection:\n",
    "        if not os.path.isfile(model_target):\n",
    "            print 'downloading...%i/%i' %(index, len(fileNames)),\n",
    "            connection.get(file_path, model_target)\n",
    "            print 'done'\n",
    "\n",
    "    model = load_model(model_target)\n",
    "\n",
    "    loss, acc = model.evaluate(x = seqs.X_train, y = seqs.y_train, verbose = 0)\n",
    "    scores.loc[fileName, 'train'] = acc\n",
    "    loss, acc = model.evaluate(x = seqs.X_validate, y = seqs.y_validate, verbose = 0)\n",
    "    scores.loc[fileName, 'validate'] = acc\n",
    "    loss, acc = model.evaluate(x = seqs.X_test, y = seqs.y_test, verbose = 0)\n",
    "    scores.loc[fileName, 'test'] = acc\n",
    "    \n",
    "print scores.loc[:, ['train','validate','test']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_scores = pd.DataFrame(np.zeros([len(fileNames),len(fileNames)]),\n",
    "                      index = fileNames,\n",
    "                      columns = fileNames) \n",
    "\n",
    "for index, fileName in enumerate(fileNames):\n",
    "    \n",
    "    sequence_path = '/Users/pablomartin/python/' + \\\n",
    "                    'DATA_structures/RNN_sequences/OneHotBinaryMinimal/' + \\\n",
    "                    dataPrep + '/' + fileName\n",
    "    seqs = pickle.load(open(sequence_path, 'rb'))       \n",
    "\n",
    "    \n",
    "\n",
    "    for cindex, compFileName in enumerate(fileNames):\n",
    "        model_target = '/Users/pablomartin/python/Models/Winners/' + compFileName[:-2] + '.hdf5'\n",
    "        model = load_model(model_target)        \n",
    "        if fileName == compFileName:\n",
    "            loss, acc = model.evaluate(x = seqs.X_test, y = seqs.y_test)\n",
    "            grid_scores.loc[compFileName, fileName] = acc\n",
    "        else:\n",
    "            X = np.concatenate([seqs.X_train, seqs.X_validate, seqs.X_test])\n",
    "            y = np.concatenate([seqs.y_train, seqs.y_validate, seqs.y_test])\n",
    "            loss, acc = model.evaluate(x = X, y = y)\n",
    "            grid_scores.loc[compFileName, fileName] = acc\n",
    "            \n",
    "print 'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
